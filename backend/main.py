from fastapi import FastAPI
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import json
import subprocess
import os

app = FastAPI()

OLLAMA_URL = "http://ollama:11434/api/generate"
INDEX_FILE = "/data/faiss.index"
META_FILE = "/data/docs_meta.json"

print("ğŸ”§ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· FAISS index ÎºÎ±Î¹ metadata...")
index = faiss.read_index(INDEX_FILE)
with open(META_FILE, "r", encoding="utf-8") as f:
    data = json.load(f)
texts = data["texts"]
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

class Question(BaseModel):
    question: str

@app.post("/api/ask")
def ask_question(q: Question):
    question_emb = model.encode([q.question]).astype("float32")
    D, I = index.search(question_emb, 5)  # top 5 related paragraphs
    context = "\n".join([texts[i] for i in I[0]])

    payload = {
        "model": "mistral:latest",
        "prompt": f"Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿Ï‚ ÏƒÏ„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î±Ï€Î¿ÏƒÏ€Î¬ÏƒÎ¼Î±Ï„Î±:\n{context}\n\nÎ•ÏÏÏ„Î·ÏƒÎ·: {q.question}\nÎ‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬:"
    }

    cmd = [
        "curl", "-s", "-X", "POST", OLLAMA_URL,
        "-H", "Content-Type: application/json",
        "-d", json.dumps(payload)
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)

    try:
        resp_json = json.loads(result.stdout)
        answer = resp_json.get("response", "").strip()
    except:
        answer = "Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ Ï„Î¿ Ollama."

    return {"answer": answer}
