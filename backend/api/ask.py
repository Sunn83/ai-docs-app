from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import faiss, json, os, re
import numpy as np
from sentence_transformers import SentenceTransformer
from urllib.parse import quote

router = APIRouter()

INDEX_FILE = "/data/faiss.index"
META_FILE = "/data/docs_meta.json"
PDF_BASE_URL = "http://144.91.115.48:8000/pdf"  # ÏƒÏ‰ÏƒÏ„ÏŒ path Î³Î¹Î± PDFs

# ğŸ”¹ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÎºÎ±Î¹ index
model = SentenceTransformer("intfloat/multilingual-e5-base", cache_folder="/root/.cache/huggingface")

if not os.path.exists(INDEX_FILE) or not os.path.exists(META_FILE):
    raise RuntimeError("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ FAISS index Î® metadata.")

index = faiss.read_index(INDEX_FILE)
with open(META_FILE, "r", encoding="utf-8") as f:
    metadata = json.load(f)

print("âœ… FAISS index ÎºÎ±Î¹ metadata Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ ÏƒÏ„Î· Î¼Î½Î®Î¼Î·.")

# -------------------- Memory Î³Î¹Î± follow-up --------------------
CHAT_HISTORY = []  # (role, text) tuples
MAX_HISTORY = 8

class Query(BaseModel):
    question: str

def clean_text(t: str) -> str:
    """ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…, Î´Î¹Î±Ï„Î·ÏÎµÎ¯ newlines"""
    if not t:
        return ""
    t = t.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")
    t = re.sub(r"[ \t]+", " ", t)
    t = re.sub(r"\n{3,}", "\n\n", t)
    return t.strip()

# -------------------- Build prompt Î³Î¹Î± LLM --------------------
def build_prompt(history, user_message, context_chunks):
    history_text = ""
    for role, content in history:
        history_text += f"{role.upper()}: {content}\n"

    context_text = "\n\n---\n\n".join(context_chunks)

    return f"""
Î£Îµ Î±Ï…Ï„ÏŒ Ï„Î¿ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î·Ï„Î¹ÎºÏŒ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ ÎµÎ¯ÏƒÎ±Î¹ Î½Î¿Î¼Î¹ÎºÏŒÏ‚ Î²Î¿Î·Î¸ÏŒÏ‚.
Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Ï€Î»Î®ÏÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ ÏƒÏ…Î¶Î®Ï„Î·ÏƒÎ·Ï‚:

{history_text}

---

ÎÎ­Î± ÎµÏÏÏ„Î·ÏƒÎ· Ï‡ÏÎ®ÏƒÏ„Î·:
USER: {user_message}

---

Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ (RAG):
{context_text}

ÎŸÎ´Î·Î³Î¯ÎµÏ‚:
- Î‘Î½ Î· ÎµÏÏÏ„Î·ÏƒÎ· ÎµÎ¯Î½Î±Î¹ follow-up, Î±Ï€Î¬Î½Ï„Î·ÏƒÎµ Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Ï‚ Ï…Ï€ÏŒÏˆÎ· Ï„Î¿ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ.
- Î‘Î½ ÏƒÎ¿Ï… Î¶Î·Ï„Î·Î¸ÎµÎ¯ "Î¬Î»Î»Î¿ Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±", Î´ÏÏƒÎµ Î½Î­Î¿ Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±.
- Î‘Î½ Î· ÎµÏÏÏ„Î·ÏƒÎ· Î­Ï‡ÎµÎ¹ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚, ÎºÎ¬Î½Îµ ÏƒÏ…Î»Î»Î¿Î³Î¹ÏƒÏ„Î¹ÎºÎ® ÎºÎ±Î¹ Ï…Ï€Î¿Î»ÏŒÎ³Î¹ÏƒÎµ Ï„Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±.
- Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÏ„Î¿ context, Î±Ï€Î¬Î½Ï„Î·ÏƒÎµ "Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±".

Î”ÏÏƒÎµ ÎºÎ±Î¸Î±ÏÎ®, Î´Î¿Î¼Î·Î¼Î­Î½Î· ÎºÎ±Î¹ ÎºÎ±Ï„Î±Î½Î¿Î·Ï„Î® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·.
"""

# -------------------- Endpoint --------------------
@router.post("/api/ask")
def ask(query: Query):
    try:
        question = query.question.strip()
        if not question:
            raise HTTPException(status_code=400, detail="Î†Î´ÎµÎ¹Î± ÎµÏÏÏ„Î·ÏƒÎ·.")

        # ğŸ”¹ Encode query
        q_emb = model.encode([question], convert_to_numpy=True)
        q_emb = q_emb.astype("float32")
        faiss.normalize_L2(q_emb)

        # ğŸ”¹ Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· FAISS
        k = 10
        D, I = index.search(q_emb, k)

        results = []
        for idx, score in zip(I[0], D[0]):
            if idx < len(metadata):
                md = metadata[idx]
                text = md.get("text", "").strip()
                if text:
                    results.append({
                        "idx": int(idx),
                        "score": float(score),
                        "filename": md.get("filename", "unknown.pdf"),
                        "page": md.get("page", 1),
                        "text": text
                    })

        if not results:
            return {"answers": [{"answer": "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·.", "score": 0}], "query": question}

        # ğŸ”¹ ÎšÏÎ¬Ï„Î± Ï„Î¹Ï‚ 3 ÎºÎ±Î»ÏÏ„ÎµÏÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
        top_results = sorted(results, key=lambda x: x["score"], reverse=True)[:3]
        context_chunks = [r["text"] for r in top_results]

        # ğŸ”¹ Î¦Ï„Î¹Î¬Ï‡Î½Î¿Ï…Î¼Îµ prompt Î¼Îµ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ
        prompt = build_prompt(CHAT_HISTORY, question, context_chunks)

        # ğŸ”¹ ÎšÎ»Î®ÏƒÎ· LLM (Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î· Î´Î¹ÎºÎ® ÏƒÎ¿Ï… ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï€Î¿Ï… ÏƒÏ„Î­Î»Î½ÎµÎ¹ prompt ÏƒÏ„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿)
        # Î“Î¹Î± Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: response_text = call_llm(prompt)
        response_text = "ğŸ“ Î ÏÎ¿ÏƒÎ¿Î¼Î¿Î¯Ï‰ÏƒÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ LLM Î³Î¹Î± Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±."  # Î±Î½Ï„Î¹ÎºÎ±Ï„Î¬ÏƒÏ„Î·ÏƒÎµ Î¼Îµ call_llm(prompt)

        # ğŸ”¹ Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· memory
        CHAT_HISTORY.append(("user", question))
        CHAT_HISTORY.append(("assistant", response_text))
        if len(CHAT_HISTORY) > MAX_HISTORY:
            CHAT_HISTORY[:] = CHAT_HISTORY[-MAX_HISTORY:]

        # ğŸ”¹ Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® formatted Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ‰Î½ Î¼Îµ PDF links
        answers = []
        for r in top_results:
            answer_text = clean_text(r["text"])
            filename_pdf = re.sub(r'\.docx?$', '.pdf', r["filename"], flags=re.IGNORECASE)
            encoded_filename = quote(filename_pdf)
            pdf_url = f"{PDF_BASE_URL}/{encoded_filename}#page={r['page']}"

            formatted = (
                f"{answer_text}\n\n"
                f"ğŸ“„ Î Î·Î³Î®: [{r['filename']}]({pdf_url})\n"
                f"ğŸ“‘ Î£ÎµÎ»Î¯Î´Î±: {r['page']}"
            )
            answers.append({"answer": formatted, "score": r["score"]})

        return {"answers": answers, "query": question, "llm_answer": response_text}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
