# backend/index_docs.py
import os
import json
from pathlib import Path
from docx import Document
from sentence_transformers import SentenceTransformer
import faiss

DATA_DIR = "/data"
DOCS_PATH = os.path.join(DATA_DIR, "docs")
INDEX_FILE = os.path.join(DATA_DIR, "faiss.index")
META_FILE = os.path.join(DATA_DIR, "docs_meta.json")

# Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ chunking
CHUNK_SIZE = 300  # Î»Î­Î¾ÎµÎ¹Ï‚ Î±Î½Î¬ chunk
CHUNK_OVERLAP = 50  # ÎµÏ€Î¹ÎºÎ¬Î»Ï…ÏˆÎ· Î»Î­Î¾ÎµÏ‰Î½

def read_docx(file_path):
    doc = Document(file_path)
    text = "\n".join([p.text for p in doc.paragraphs if p.text.strip() != ""])
    return text

def chunk_text(text, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):
    words = text.split()
    chunks = []
    i = 0
    while i < len(words):
        chunk = " ".join(words[i:i+chunk_size])
        chunks.append(chunk)
        i += chunk_size - overlap
    return chunks

def load_docs():
    metadata = []
    all_chunks = []
    for fname in os.listdir(DOCS_PATH):
        if not fname.lower().endswith(".docx"):
            continue
        path = os.path.join(DOCS_PATH, fname)
        text = read_docx(path)
        chunks = chunk_text(text)
        for idx, chunk in enumerate(chunks):
            metadata.append({
                "filename": fname,
                "chunk_id": idx,
                "text": chunk
            })
            all_chunks.append(chunk)
    return all_chunks, metadata

def create_faiss_index(embeddings):
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index

def main():
    print("ğŸ“„ Î’ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÏ‡ÎµÎ¯Î± Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±...")
    chunks, metadata = load_docs()
    print(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(chunks)} chunks Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±.")

    print("ğŸ” Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… embeddings...")
    model = SentenceTransformer("thenlper/gte-large")

    print("ğŸ§  Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± embeddings...")
    embeddings = model.encode(chunks, convert_to_numpy=True)

    print("ğŸ’¾ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± FAISS index...")
    index = create_faiss_index(embeddings)
    faiss.write_index(index, INDEX_FILE)

    with open(META_FILE, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    print("âœ… Indexing Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î¼Îµ ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î±!")

if __name__ == "__main__":
    main()
